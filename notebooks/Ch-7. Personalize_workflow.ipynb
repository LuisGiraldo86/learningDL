{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Built-in Training and Evaluation Loops\n",
    "\n",
    "Let us start for the most basic workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n",
      "Epoch 1/3\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8623 - loss: 0.4506 - val_accuracy: 0.9588 - val_loss: 0.1407\n",
      "Epoch 2/3\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9526 - loss: 0.1638 - val_accuracy: 0.9682 - val_loss: 0.1144\n",
      "Epoch 3/3\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9643 - loss: 0.1257 - val_accuracy: 0.9725 - val_loss: 0.1009\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9692 - loss: 0.1024\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# create a model within a function to re-use it\n",
    "def get_mnist_model():\n",
    "    inputs = keras.Input(shape=(28 * 28,))\n",
    "    features = layers.Dense(512, activation=\"relu\")(inputs)\n",
    "    features = layers.Dropout(0.5)(features)\n",
    "    outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "# load data and reserve some part for validation\n",
    "(images, labels), (test_images, test_labels) = mnist.load_data()\n",
    "images = images.reshape((60000, 28 * 28)).astype(\"float32\") / 255\n",
    "test_images = test_images.reshape((10000, 28 * 28)).astype(\"float32\") / 255\n",
    "train_images, val_images = images[10000:], images[:10000]\n",
    "train_labels, val_labels = labels[10000:], labels[:10000]\n",
    "\n",
    "model = get_mnist_model()\n",
    "model.compile(\n",
    "    optimizer=\"rmsprop\",\n",
    "    loss     =\"sparse_categorical_crossentropy\",\n",
    "    metrics  =[\"accuracy\"]\n",
    ")\n",
    "model.fit(\n",
    "    train_images, train_labels,\n",
    "    epochs=3,\n",
    "    validation_data=(val_images, val_labels)\n",
    ")\n",
    "test_metrics = model.evaluate(test_images, test_labels)\n",
    "predictions = model.predict(test_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a couple of ways you can customize this simple workflow:\n",
    "1. Provide your own custom metrics.\n",
    "2. Pass callbacks to the `fit()` method to schedule actions to be taken at specific points during training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commonly used metrics for classification and regression are already part of the built-in `keras.metrics` module, and most of the time that’s what you will use. But if you’re doing anything out of the ordinary, you will need to be able\n",
    "to write your own metrics.\n",
    "\n",
    "A Keras metric is a subclass of the `keras.metrics.Metric` class. Like layers, a metric has an internal state stored in TensorFlow variables. Unlike layers, these variables aren’t updated via backpropagation, so you have to write the state-update logic yourself, which happens in the `update_state()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing a custom metric by subclassing the Metric class\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "class RootMeanSquaredError(keras.metrics.Metric):\n",
    "\n",
    "    # Define the state variables in the constructor. Like for layers, you\n",
    "    # have access to the add_weight() method.\n",
    "    def __init__(self, name=\"rmse\", **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.mse_sum = self.add_weight(name=\"mse_sum\", initializer=\"zeros\")\n",
    "        self.total_samples = self.add_weight(\n",
    "        name=\"total_samples\", initializer=\"zeros\", dtype=\"int32\")\n",
    "\n",
    "    # Implement the state update logic in update_state(). The y_true argument\n",
    "    # is the targets (or labels) for one batch, while y_pred represents the\n",
    "    # corresponding predictions from the model.\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_true = tf.one_hot(y_true, depth=tf.shape(y_pred)[1])\n",
    "        mse = tf.reduce_sum(tf.square(y_true - y_pred))\n",
    "        self.mse_sum.assign_add(mse)\n",
    "        num_samples = tf.shape(y_pred)[0]\n",
    "        self.total_samples.assign_add(num_samples)\n",
    "\n",
    "    # use the result() method to return the current value of the metric:\n",
    "    def result(self):\n",
    "        return tf.sqrt(self.mse_sum / tf.cast(self.total_samples, tf.float32))\n",
    "    \n",
    "    # expose a way to reset the metric state without having to reinstantiate it\n",
    "    def reset_state(self):\n",
    "        self.mse_sum.assign(0.)\n",
    "        self.total_samples.assign(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8635 - loss: 0.4483 - rmse: 0.4375 - val_accuracy: 0.9593 - val_loss: 0.1426 - val_rmse: 0.2490\n",
      "Epoch 2/3\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9534 - loss: 0.1586 - rmse: 0.2661 - val_accuracy: 0.9681 - val_loss: 0.1116 - val_rmse: 0.2186\n",
      "Epoch 3/3\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9635 - loss: 0.1316 - rmse: 0.2389 - val_accuracy: 0.9719 - val_loss: 0.1001 - val_rmse: 0.2075\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9694 - loss: 0.1103 - rmse: 0.2152\n"
     ]
    }
   ],
   "source": [
    "model = get_mnist_model()\n",
    "model.compile(\n",
    "    optimizer=\"rmsprop\",\n",
    "    loss     =\"sparse_categorical_crossentropy\",\n",
    "    metrics  =[\"accuracy\", RootMeanSquaredError()]\n",
    ")\n",
    "model.fit(\n",
    "    train_images, train_labels,\n",
    "    epochs=3,\n",
    "    validation_data=(val_images, val_labels)\n",
    ")\n",
    "test_metrics = model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us see an example of how to use callbacks during model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8638 - loss: 0.4468 - val_accuracy: 0.9594 - val_loss: 0.1413\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9534 - loss: 0.1627 - val_accuracy: 0.9682 - val_loss: 0.1144\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9624 - loss: 0.1324 - val_accuracy: 0.9730 - val_loss: 0.1020\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9692 - loss: 0.1084 - val_accuracy: 0.9751 - val_loss: 0.1004\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9714 - loss: 0.1066 - val_accuracy: 0.9776 - val_loss: 0.0920\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9744 - loss: 0.0954 - val_accuracy: 0.9784 - val_loss: 0.0972\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9758 - loss: 0.0865 - val_accuracy: 0.9787 - val_loss: 0.0931\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9776 - loss: 0.0814 - val_accuracy: 0.9770 - val_loss: 0.0912\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9792 - loss: 0.0767 - val_accuracy: 0.9800 - val_loss: 0.0899\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9807 - loss: 0.0713 - val_accuracy: 0.9792 - val_loss: 0.0831\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f9f3517fb60>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Callbacks are passed to the model via the callbacks argument in fit(), which takes a list of\n",
    "# callbacks. One can pass any number of callbacks.\n",
    "callbacks_list = [\n",
    "    keras.callbacks.EarlyStopping( # Interrupts training when improvement stops\n",
    "        monitor=\"val_accuracy\", # Monitors the model’s validation accuracy\n",
    "        patience=2, # Interrupts training when accuracy has stopped improving for two epochs\n",
    "    ),\n",
    "    keras.callbacks.ModelCheckpoint( # Saves the current weights after every epoch\n",
    "        filepath=\"checkpoint_path.keras\", # Path to the destination model file\n",
    "        monitor=\"val_loss\",  # These two arguments mean you won’t overwrite the model file unless val_loss\n",
    "        save_best_only=True, # has improved, which allows you to keep the best model seen during training.\n",
    "    )\n",
    "]\n",
    "model = get_mnist_model()\n",
    "model.compile(\n",
    "    optimizer=\"rmsprop\",\n",
    "    loss     =\"sparse_categorical_crossentropy\",\n",
    "    metrics  =[\"accuracy\"] # You monitor accuracy, so it should be part of the model’s metrics.\n",
    ")\n",
    "model.fit(\n",
    "    train_images, train_labels,\n",
    "    epochs=10,\n",
    "    callbacks=callbacks_list,\n",
    "    validation_data=(val_images, val_labels)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A good way to have more control on the experiments is to \"see\" what is happening during the training process. A good tool to accomplish this is TensorBoard. Let us see how to use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.8653 - loss: 0.4543 - val_accuracy: 0.9570 - val_loss: 0.1500\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9515 - loss: 0.1675 - val_accuracy: 0.9681 - val_loss: 0.1132\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9615 - loss: 0.1349 - val_accuracy: 0.9715 - val_loss: 0.1096\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9666 - loss: 0.1145 - val_accuracy: 0.9727 - val_loss: 0.1003\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9722 - loss: 0.1019 - val_accuracy: 0.9766 - val_loss: 0.0923\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9742 - loss: 0.0904 - val_accuracy: 0.9771 - val_loss: 0.1000\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9759 - loss: 0.0844 - val_accuracy: 0.9757 - val_loss: 0.0989\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9775 - loss: 0.0824 - val_accuracy: 0.9791 - val_loss: 0.0919\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9803 - loss: 0.0747 - val_accuracy: 0.9805 - val_loss: 0.0930\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9811 - loss: 0.0693 - val_accuracy: 0.9801 - val_loss: 0.0927\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f9f366f0bf0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_mnist_model()\n",
    "model.compile(\n",
    "    optimizer=\"rmsprop\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "tensorboard = keras.callbacks.TensorBoard(\n",
    "    log_dir=\"/mnt/0A2AAC152AABFBB7/sideProjects/deepLearning/images\",\n",
    ")\n",
    "model.fit(\n",
    "    train_images, train_labels,\n",
    "    epochs=10,\n",
    "    validation_data=(val_images, val_labels),\n",
    "    callbacks=[tensorboard]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-ebf00ca3932ed446\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-ebf00ca3932ed446\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir /mnt/0A2AAC152AABFBB7/sideProjects/deepLearning/images"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
