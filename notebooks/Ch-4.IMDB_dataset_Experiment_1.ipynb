{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aR8p68PkRul5"
      },
      "source": [
        "# Experimenting with Deep Learning and IMDB dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "m0ATdXZJSIhy"
      },
      "outputs": [],
      "source": [
        "# imports\n",
        "import os\n",
        "\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import mlflow\n",
        "\n",
        "from mlflow.tracking import MlflowClient\n",
        "from tensorflow import keras\n",
        "from keras import layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The following cells are exactly the same from the worked example in Chapter 4 from Chollet's book."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jqyoSLURSV4S",
        "outputId": "84529676-1bbf-4ebc-fb88-c99449177097"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "\u001b[1m17464789/17464789\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "# Loading the IMDB dataset\n",
        "\n",
        "(train_data, train_labels), (test_data, test_labels) = tf.keras.datasets.imdb.load_data(num_words=10000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "U0Kt21_4SYkM"
      },
      "outputs": [],
      "source": [
        "# Encoding the integer sequences via multi-hot encoding\n",
        "\n",
        "def vectorize_sequences(sequences, dimension=10000):\n",
        "\n",
        "    results = np.zeros((len(sequences), dimension))\n",
        "    for i, sequence in enumerate(sequences):\n",
        "        for j in sequence:\n",
        "            results[i, j] = 1.\n",
        "    return results\n",
        "\n",
        "x_train = vectorize_sequences(train_data)\n",
        "x_test = vectorize_sequences(test_data)\n",
        "\n",
        "y_train = np.asarray(train_labels).astype(\"float32\")\n",
        "y_test = np.asarray(test_labels).astype(\"float32\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Fu0dsvSnSerj"
      },
      "outputs": [],
      "source": [
        "# Setting aside a validation set\n",
        "\n",
        "x_val = x_train[:10000]\n",
        "partial_x_train = x_train[10000:]\n",
        "\n",
        "y_val = y_train[:10000]\n",
        "partial_y_train = y_train[10000:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here we add a basic `MLflow` functionality to track the experiments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mWvvXIdWSkEL",
        "outputId": "f265d1b6-db1e-42ed-a12d-792e1c579947"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024/04/29 11:46:46 INFO mlflow.tracking.fluent: Experiment with name 'deepLearning_IMDB_dataset' does not exist. Creating a new experiment.\n"
          ]
        }
      ],
      "source": [
        "# Initialize client and experiment\n",
        "\n",
        "EXPERIMENT_NAME = \"deepLearning_IMDB_dataset\"\n",
        "client = MlflowClient()\n",
        "mlflow.set_experiment(EXPERIMENT_NAME)\n",
        "exp = client.get_experiment_by_name(EXPERIMENT_NAME)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We create a list with different layer sizes to check the performance variation. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ZT97FK2DS0Us"
      },
      "outputs": [],
      "source": [
        "units_2_hidden = [(16, 16), (32, 32), (64,64)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XATUcedwS5l0",
        "outputId": "306b5155-c7f3-4837-a070-947ddcacdd15"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-04-29 11:46:47.869770: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 600000000 exceeds 10% of free system memory.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m11/30\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5859 - loss: 0.6691"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-04-29 11:46:49.299893: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 20480000 exceeds 10% of free system memory.\n",
            "2024-04-29 11:46:49.299965: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 20480000 exceeds 10% of free system memory.\n",
            "2024-04-29 11:46:49.300000: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 20480000 exceeds 10% of free system memory.\n",
            "2024-04-29 11:46:49.300033: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 20480000 exceeds 10% of free system memory.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - accuracy: 0.6721 - loss: 0.6239 - val_accuracy: 0.8414 - val_loss: 0.4519\n",
            "Epoch 2/4\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8813 - loss: 0.3906 - val_accuracy: 0.8712 - val_loss: 0.3454\n",
            "Epoch 3/4\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9125 - loss: 0.2799 - val_accuracy: 0.8811 - val_loss: 0.3045\n",
            "Epoch 4/4\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9245 - loss: 0.2264 - val_accuracy: 0.8880 - val_loss: 0.2808\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8799 - loss: 0.2936\n",
            "Epoch 1/4\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.6975 - loss: 0.5827 - val_accuracy: 0.8403 - val_loss: 0.3908\n",
            "Epoch 2/4\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8939 - loss: 0.3095 - val_accuracy: 0.8880 - val_loss: 0.2921\n",
            "Epoch 3/4\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9222 - loss: 0.2265 - val_accuracy: 0.8890 - val_loss: 0.2805\n",
            "Epoch 4/4\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9390 - loss: 0.1773 - val_accuracy: 0.8797 - val_loss: 0.3011\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8705 - loss: 0.3179\n",
            "Epoch 1/4\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - accuracy: 0.6964 - loss: 0.5885 - val_accuracy: 0.8720 - val_loss: 0.3484\n",
            "Epoch 2/4\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8884 - loss: 0.3083 - val_accuracy: 0.8766 - val_loss: 0.3055\n",
            "Epoch 3/4\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.9127 - loss: 0.2311 - val_accuracy: 0.8855 - val_loss: 0.2796\n",
            "Epoch 4/4\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9298 - loss: 0.1853 - val_accuracy: 0.8552 - val_loss: 0.3734\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8456 - loss: 0.3938\n"
          ]
        }
      ],
      "source": [
        "count = 0\n",
        "for units in units_2_hidden:\n",
        "\n",
        "    model = keras.Sequential([\n",
        "                  layers.Dense(units[0], activation='relu'),\n",
        "                  layers.Dense(units[1], activation='relu'),\n",
        "                  layers.Dense(1, activation=\"sigmoid\")\n",
        "              ])\n",
        "\n",
        "    model.compile(\n",
        "          optimizer=\"rmsprop\",\n",
        "          loss=\"binary_crossentropy\",\n",
        "          metrics=[\"accuracy\"]\n",
        "      )\n",
        "\n",
        "    history = model.fit(\n",
        "                    partial_x_train,\n",
        "                    partial_y_train,\n",
        "                    epochs=4,\n",
        "                    batch_size=512,\n",
        "                    validation_data=(x_val, y_val)\n",
        "                )\n",
        "\n",
        "    hist_dict = history.history\n",
        "    test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
        "\n",
        "\n",
        "    with mlflow.start_run():\n",
        "        mlflow.set_tag(\"model\", \"Base_relu_{}\".format(count))\n",
        "        mlflow.log_param(\"units_1st_layer\", units[0])\n",
        "        mlflow.log_param(\"units_2nd_layer\", units[1])\n",
        "        mlflow.log_param(\"hidden_activation\", 'relu')\n",
        "        mlflow.log_param(\"epochs\", 4)\n",
        "        mlflow.log_param(\"batch_size\", 512)\n",
        "        mlflow.log_metric(\"accuracy\", test_accuracy)\n",
        "        mlflow.log_metric(\"loss\", test_loss)\n",
        "    count+=1\n",
        "\n",
        "    del hist_dict\n",
        "    del history\n",
        "    del model\n",
        "\n",
        "runs = mlflow.search_runs()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The above code can be optimized using a function to \"set up\" the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A3JHdOneTcH-",
        "outputId": "09c1b3d2-cdda-41c0-a1cc-6dc8ddd866d6"
      },
      "outputs": [],
      "source": [
        "PATH_TO_RUNS = \"/mnt/0A2AAC152AABFBB7/sideProjects/deepLearning/mlflow_runs\"\n",
        "runs.to_csv(\n",
        "    os.path.join(PATH_TO_RUNS, 'imdb_runs_1.csv')\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "XQ-zULNQThbG",
        "outputId": "582f88ab-b8c2-44c7-a716-024789df6fc8"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>experiment_id</th>\n",
              "      <th>status</th>\n",
              "      <th>metrics.loss</th>\n",
              "      <th>metrics.accuracy</th>\n",
              "      <th>params.units_1st_layer</th>\n",
              "      <th>params.units_2nd_layer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>926124755463801135</td>\n",
              "      <td>FINISHED</td>\n",
              "      <td>0.385586</td>\n",
              "      <td>0.84884</td>\n",
              "      <td>64</td>\n",
              "      <td>64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>926124755463801135</td>\n",
              "      <td>FINISHED</td>\n",
              "      <td>0.313741</td>\n",
              "      <td>0.87392</td>\n",
              "      <td>32</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>926124755463801135</td>\n",
              "      <td>FINISHED</td>\n",
              "      <td>0.294502</td>\n",
              "      <td>0.88060</td>\n",
              "      <td>16</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        experiment_id    status  metrics.loss  metrics.accuracy  \\\n",
              "0  926124755463801135  FINISHED      0.385586           0.84884   \n",
              "1  926124755463801135  FINISHED      0.313741           0.87392   \n",
              "2  926124755463801135  FINISHED      0.294502           0.88060   \n",
              "\n",
              "  params.units_1st_layer params.units_2nd_layer  \n",
              "0                     64                     64  \n",
              "1                     32                     32  \n",
              "2                     16                     16  "
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "runs[['experiment_id', 'status', 'metrics.loss', 'metrics.accuracy', 'params.units_1st_layer', 'params.units_2nd_layer']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2pChYW2wVWsF"
      },
      "outputs": [],
      "source": [
        "# import local modules\n",
        "import sys\n",
        "sys.path.append('/mnt/0A2AAC152AABFBB7/sideProjects/deepLearning/deeplearning')\n",
        "from deeplearning.deep_utils import imdb_model_setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "count = 0\n",
        "for units in units_2_hidden:\n",
        "\n",
        "    model, history = imdb_model_setup(\n",
        "        units_layer1=units[0],\n",
        "        units_layer2=units[1],\n",
        "        activ_func=\"relu\",\n",
        "        X_train=partial_x_train,\n",
        "        y_train=partial_y_train,\n",
        "        X_val=x_val,\n",
        "        y_val=y_val\n",
        "    )\n",
        "\n",
        "    hist_dict = history.history\n",
        "    test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
        "\n",
        "\n",
        "    with mlflow.start_run():\n",
        "        mlflow.set_tag(\"model\", \"Base_relu_{}\".format(count))\n",
        "        mlflow.log_param(\"units_1st_layer\", units[0])\n",
        "        mlflow.log_param(\"units_2nd_layer\", units[1])\n",
        "        mlflow.log_param(\"hidden_activation\", 'relu')\n",
        "        mlflow.log_param(\"epochs\", 4)\n",
        "        mlflow.log_param(\"batch_size\", 512)\n",
        "        mlflow.log_metric(\"accuracy\", test_accuracy)\n",
        "        mlflow.log_metric(\"loss\", test_loss)\n",
        "    count+=1\n",
        "\n",
        "    del hist_dict\n",
        "    del history\n",
        "    del model\n",
        "\n",
        "runs = mlflow.search_runs()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
